<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch | It&#39;s Kartik Patath</title>
    <link>https://kartiksonu.github.io/tag/pytorch/</link>
      <atom:link href="https://kartiksonu.github.io/tag/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <description>Pytorch</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 27 Apr 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kartiksonu.github.io/media/icon_hu2e9c6cf66d3af87fdee2833acc3b1756_12919_512x512_fill_lanczos_center_3.png</url>
      <title>Pytorch</title>
      <link>https://kartiksonu.github.io/tag/pytorch/</link>
    </image>
    
    <item>
      <title>Motion forecasting</title>
      <link>https://kartiksonu.github.io/project/motion-forcasting/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://kartiksonu.github.io/project/motion-forcasting/</guid>
      <description>&lt;p&gt;A better understanding of agentsâ€™ behaviour in a dynamic traffic environment is required for an efficient modelling and navigation of autonomous vehicles. In this project we plan to address the problem of motion forecasting of traffic actors through experimentation on the Argoverse Motion Forecasting dataset. We attempt to tackle this challenge using generative adversarial networks (GANs) and compare out results with baseline methods of seq-to-seq prediction and social LSTM provided by the Argoverse Challenge.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Curiosity-Driven Exploration</title>
      <link>https://kartiksonu.github.io/project/curiosity-based-learning/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://kartiksonu.github.io/project/curiosity-based-learning/</guid>
      <description>&lt;p&gt;Implemented the idea of curiosity based agent which learns explores the environment using self-supervised prediction. The environment used for this project is the Minecraft environment, to solve the Navigation task of MineRL Challenge, NeurIPS 2019.&lt;/p&gt;
&lt;p&gt;Rewards from the environment depict how well the agent is performing in the required task. Majority of the techniques in reinforcement learning depend upon the reward from the environment to select the actions which maximize the overall reward. However, in real-world scenario such explicit rewards might be sparse or even not available to the agent. The idea of Curiosity-Driven learning, is to build a reward function that is intrinsic to the agent (generated by the agent itself). In this work, we compare two Curiosity-driven learning methods (ICM and RND) for navigation task in MineRL Environment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DQN - breakout</title>
      <link>https://kartiksonu.github.io/project/dqn/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://kartiksonu.github.io/project/dqn/</guid>
      <description>&lt;p&gt;As a part of Reinforcemnt learning course work I implemented a dueling DQN network to train the an agent to play Atari-breakout-v4. The training was performed using Google Cloud Platform (GCP).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
