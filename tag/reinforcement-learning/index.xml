<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning | It&#39;s Kartik Patath</title>
    <link>https://kartiksonu.github.io/tag/reinforcement-learning/</link>
      <atom:link href="https://kartiksonu.github.io/tag/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Reinforcement Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 27 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kartiksonu.github.io/media/icon_hu2e9c6cf66d3af87fdee2833acc3b1756_12919_512x512_fill_lanczos_center_3.png</url>
      <title>Reinforcement Learning</title>
      <link>https://kartiksonu.github.io/tag/reinforcement-learning/</link>
    </image>
    
    <item>
      <title>Curiosity-Driven Exploration</title>
      <link>https://kartiksonu.github.io/project/curiosity-based-learning/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://kartiksonu.github.io/project/curiosity-based-learning/</guid>
      <description>&lt;p&gt;Implemented the idea of curiosity based agent which learns explores the environment using self-supervised prediction. The environment used for this project is the Minecraft environment, to solve the Navigation task of MineRL Challenge, NeurIPS 2019.&lt;/p&gt;
&lt;p&gt;Rewards from the environment depict how well the agent is performing in the required task. Majority of the techniques in reinforcement learning depend upon the reward from the environment to select the actions which maximize the overall reward. However, in real-world scenario such explicit rewards might be sparse or even not available to the agent. The idea of Curiosity-Driven learning, is to build a reward function that is intrinsic to the agent (generated by the agent itself). In this work, we compare two Curiosity-driven learning methods (ICM and RND) for navigation task in MineRL Environment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DQN - breakout</title>
      <link>https://kartiksonu.github.io/project/dqn/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://kartiksonu.github.io/project/dqn/</guid>
      <description>&lt;p&gt;As a part of Reinforcemnt learning course work I implemented a dueling DQN network to train the an agent to play Atari-breakout-v4. The training was performed using Google Cloud Platform (GCP).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
